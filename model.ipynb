{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: Chain, Dense, relu, ADAM, mse, gradient, params, Optimise\n",
    "using Statistics: mean\n",
    "include(\"preprocessing.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function prepare_data(input_dir::String)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for csv in readdir(input_dir)\n",
    "        df = CSV.read(joinpath(input_dir, csv), DataFrame)\n",
    "        if size(df)[1] < 500\n",
    "            continue\n",
    "        end\n",
    "        push!(inputs, Matrix{Float32}(df[1:500, 1:end-1]))\n",
    "        push!(outputs, sum(df[1:500, end]))\n",
    "    end\n",
    "    \n",
    "    # Find the length of the longest input array\n",
    "    max_length = maximum(size(input, 1) for input in inputs)\n",
    "\n",
    "    # Pad input arrays with zeros to match the longest array's length\n",
    "    padded_inputs = []\n",
    "    for input in inputs\n",
    "        rows_to_pad = max_length - size(input, 1)\n",
    "        padded_input = vcat(input, zeros(Float32, rows_to_pad, size(input, 2)))\n",
    "        push!(padded_inputs, padded_input)\n",
    "    end\n",
    "\n",
    "    (padded_inputs, outputs')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = prepare_data(\"assets/anomalous\")\n",
    "\n",
    "rows = [size(arr, 1)[1] for arr in inputs]\n",
    "numCSVs = size(inputs)[1]\n",
    "SEQ_MIN = minimum(rows)\n",
    "SEQ_MAX = maximum(rows)\n",
    "\n",
    "println(\"Number of CSVs: $numCSVs \" * \"Min Rows: $SEQ_MIN \" * \"Max Rows: $SEQ_MAX \" * \"Number of columns: $(size(inputs[1])[2])\")\n",
    "println(\"Output dim: $(size(outputs))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(inputs, outputs, epochs)\n",
    "    model = Flux.Chain(\n",
    "                Dense(4, 64, relu),\n",
    "                Dense(64, 16, relu),\n",
    "                Dense(16, 1)\n",
    "            )\n",
    "\n",
    "    # Define the optimizer\n",
    "    opt = ADAM(0.01)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss(x, y) = mse(model(x), y)\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 1\n",
    "    num_batches = div(length(outputs), batch_size)\n",
    "    num_epochs = epochs\n",
    "\n",
    "    for epoch in 1:num_epochs\n",
    "        epoch_loss = 0.0\n",
    "        for i in 1:num_batches\n",
    "            idx = (i-1)*batch_size+1:i*batch_size\n",
    "            x_batch = hcat(inputs[idx]...)'  # Transpose the input data\n",
    "            y_batch = reshape(outputs[idx], 1, length(outputs[idx]))\n",
    "            grads = Flux.gradient(() -> loss(x_batch, y_batch), params(model))\n",
    "            Flux.Optimise.update!(opt, params(model), grads)\n",
    "            epoch_loss += loss(x_batch, y_batch)\n",
    "        end\n",
    "        @show epoch, epoch_loss / num_batches\n",
    "    end\n",
    "\n",
    "    # Predict the outputs\n",
    "    X_test = rand(Float32, 4, 10)\n",
    "    Y_pred = model(X_test)\n",
    "\n",
    "    model\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(inputs, outputs, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
