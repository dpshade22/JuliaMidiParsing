{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reconstruct_midi_file (generic function with 1 method)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux: Chain, Dense, relu, ADAM, mse, gradient, params, Optimise\n",
    "using Statistics: mean\n",
    "include(\"preprocessing.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_data (generic function with 1 method)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_data(input_dir::String)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "\n",
    "    for csv in readdir(input_dir)\n",
    "        df = CSV.read(joinpath(input_dir, csv), DataFrame)\n",
    "        if size(df)[1] < 500\n",
    "            continue\n",
    "        end\n",
    "        push!(inputs, Matrix{Float32}(df[1:500, 1:end-1]))\n",
    "        push!(outputs, sum(df[1:500, end]))\n",
    "    end\n",
    "    \n",
    "    # Find the length of the longest input array\n",
    "    max_length = maximum(size(input, 1) for input in inputs)\n",
    "\n",
    "    # Pad input arrays with zeros to match the longest array's length\n",
    "    padded_inputs = []\n",
    "    for input in inputs\n",
    "        rows_to_pad = max_length - size(input, 1)\n",
    "        padded_input = vcat(input, zeros(Float32, rows_to_pad, size(input, 2)))\n",
    "        push!(padded_inputs, padded_input)\n",
    "    end\n",
    "\n",
    "    (padded_inputs, outputs')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CSVs: 8550 Min Rows: 500 Max Rows: 500 Number of columns: 4\n",
      "Output dim: (8550,)\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = prepare_data(\"assets/anomalous\")\n",
    "\n",
    "rows = [size(arr, 1)[1] for arr in inputs]\n",
    "numCSVs = size(inputs)[1]\n",
    "SEQ_MIN = minimum(rows)\n",
    "SEQ_MAX = maximum(rows)\n",
    "\n",
    "println(\"Number of CSVs: $numCSVs \" * \"Min Rows: $SEQ_MIN \" * \"Max Rows: $SEQ_MAX \" * \"Number of columns: $(size(inputs[1])[2])\")\n",
    "println(\"Output dim: $(size(outputs))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_model (generic function with 1 method)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_model(inputs, outputs, epochs)\n",
    "    model = Flux.Chain(\n",
    "                Dense(4, 64, relu),\n",
    "                Dense(64, 16, relu),\n",
    "                Dense(16, 1)\n",
    "            )\n",
    "\n",
    "    # Define the optimizer\n",
    "    opt = ADAM(0.01)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss(x, y) = mse(model(x), y)\n",
    "\n",
    "    # Train the model\n",
    "    batch_size = 1\n",
    "    num_batches = div(length(outputs), batch_size)\n",
    "    num_epochs = epochs\n",
    "\n",
    "    for epoch in 1:num_epochs\n",
    "        epoch_loss = 0.0\n",
    "        for i in 1:num_batches\n",
    "            idx = (i-1)*batch_size+1:i*batch_size\n",
    "            x_batch = hcat(inputs[idx]...)'  # Transpose the input data\n",
    "            y_batch = reshape(outputs[idx], 1, length(outputs[idx]))\n",
    "            grads = Flux.gradient(() -> loss(x_batch, y_batch), params(model))\n",
    "            Flux.Optimise.update!(opt, params(model), grads)\n",
    "            epoch_loss += loss(x_batch, y_batch)\n",
    "        end\n",
    "        @show epoch, epoch_loss / num_batches\n",
    "    end\n",
    "\n",
    "    # Predict the outputs\n",
    "    X_test = rand(Float32, 4, 10)\n",
    "    Y_pred = model(X_test)\n",
    "\n",
    "    model\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: loss function expects size(ŷ) = (1, 500) to match size(y) = (1, 1)",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: loss function expects size(ŷ) = (1, 500) to match size(y) = (1, 1)",
      "",
      "Stacktrace:",
      "  [1] _check_sizes(ŷ::Matrix{Float32}, y::Matrix{Any})",
      "    @ Flux.Losses C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\losses\\utils.jl:31",
      "  [2] rrule",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\losses\\utils.jl:38 [inlined]",
      "  [3] rrule",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\ChainRulesCore\\a4mIA\\src\\rules.jl:134 [inlined]",
      "  [4] chain_rrule",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\chainrules.jl:223 [inlined]",
      "  [5] macro expansion",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0 [inlined]",
      "  [6] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:9 [inlined]",
      "  [7] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\losses\\functions.jl:46 [inlined]",
      "  [8] _pullback(::Zygote.Context{true}, ::Flux.Losses.var\"##mse#14\", ::typeof(mean), ::typeof(mse), ::Matrix{Float32}, ::Matrix{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      "  [9] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\losses\\functions.jl:45 [inlined]",
      " [10] _pullback(::Zygote.Context{true}, ::typeof(mse), ::Matrix{Float32}, ::Matrix{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [11] _pullback",
      "    @ .\\In[113]:12 [inlined]",
      " [12] _pullback(::Zygote.Context{true}, ::var\"#loss#173\"{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}}, ::LinearAlgebra.Adjoint{Float32, Matrix{Float32}}, ::Matrix{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [13] _pullback",
      "    @ .\\In[113]:25 [inlined]",
      " [14] _pullback(::Zygote.Context{true}, ::var\"#172#174\"{var\"#loss#173\"{Chain{Tuple{Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(relu), Matrix{Float32}, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}}, Matrix{Any}, LinearAlgebra.Adjoint{Float32, Matrix{Float32}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [15] pullback(f::Function, ps::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface.jl:384",
      " [16] gradient(f::Function, args::Zygote.Params{Zygote.Buffer{Any, Vector{Any}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface.jl:96",
      " [17] train_model(inputs::Vector{Any}, outputs::Vector{Any}, epochs::Int64)",
      "    @ Main .\\In[113]:25",
      " [18] top-level scope",
      "    @ In[114]:1"
     ]
    }
   ],
   "source": [
    "train_model(inputs, outputs, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
