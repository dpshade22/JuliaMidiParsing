{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reconstruct_midi_file (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux, Zygote\n",
    "using Flux.Data: DataLoader\n",
    "using Statistics: mean\n",
    "using JLD2\n",
    "include(\"preprocessing.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prepare_dataloader (generic function with 3 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prepare_dataloader(input_dir::String, train_ratio::Float64=0.8, batch_size::Int=32)\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    println(\"Reading data from $(input_dir)...\")\n",
    "    for csv in readdir(input_dir)\n",
    "        df = CSV.read(joinpath(input_dir, csv), DataFrame)\n",
    "        if size(df)[1] < 500\n",
    "            continue\n",
    "        end\n",
    "        push!(inputs, Matrix{Float32}(df[1:500, 1:end-1])')\n",
    "        push!(outputs, sum(df[1:500, end]))\n",
    "    end\n",
    "    \n",
    "    # Find the length of the longest input array\n",
    "    max_length = maximum(size(input, 1) for input in inputs)\n",
    "    println(\"Padding inputs to length $(max_length)...\")\n",
    "    # Pad input arrays with zeros to match the longest array's length\n",
    "    padded_inputs = []\n",
    "    for input in inputs\n",
    "        rows_to_pad = max_length - size(input, 1)\n",
    "        padded_input = vcat(input, zeros(Float32, rows_to_pad, size(input, 2)))\n",
    "        push!(padded_inputs, padded_input)\n",
    "    end\n",
    "\n",
    "    println(\"Batching data...\")\n",
    "    # Split the data into train and validation sets\n",
    "    num_train = Int(round(length(padded_inputs) * train_ratio))\n",
    "    train_inputs = padded_inputs[1:num_train]\n",
    "    train_outputs = outputs[1:num_train]\n",
    "    val_inputs = padded_inputs[num_train+1:end]\n",
    "    val_outputs = outputs[num_train+1:end]\n",
    "\n",
    "    train_data = Flux.Data.DataLoader((train_inputs, train_outputs), batchsize=batch_size, shuffle=true)\n",
    "    val_data = Flux.Data.DataLoader((val_inputs, val_outputs), batchsize=batch_size, shuffle=true)\n",
    "    println(\"Done preparing data.\")\n",
    "\n",
    "    return train_data, val_data\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from assets/anomalous...\n",
      "Padding inputs to length 4...\n",
      "Batching data...\n",
      "Done preparing data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(DataLoader(::Tuple{Vector{Any}, Vector{Any}}, shuffle=true, batchsize=32), DataLoader(::Tuple{Vector{Any}, Vector{Any}}, shuffle=true, batchsize=32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set, val_set = prepare_dataloader(\"assets/anomalous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Many-to-one RNN architecture\n",
    "model = Flux.Recur(Flux.LSTM(4, 64), 500)\n",
    "\n",
    "loss(x, y) = Flux.mse(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Params([Float32[0.10702626 0.01696822 -0.065254584 0.092855886; -0.10495285 0.13590126 -0.06654843 -0.14827868; … ; 0.08450505 0.07369942 -0.12488393 -0.028589867; -0.09073787 -0.04979955 -0.10373106 0.12580813], Float32[0.009323896 -0.10380827 … -0.05286085 0.027610043; 0.083879985 -0.090319835 … 0.029768014 -0.09390886; … ; 0.0499807 0.08628668 … 0.10984822 0.08031799; -0.0045832857 -0.09732817 … -0.031048324 0.010956693], Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.0; 0.0; … ; 0.0; 0.0;;], Float32[0.009871284 0.060647424 … 0.010794526 -0.03783303], Float32[0.0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Flux.setup(Adam(1e-2), model)\n",
    "ps = Flux.params(model) # Get the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "DimensionMismatch: new dimensions (500, 4, 32) must be consistent with array size 32",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: new dimensions (500, 4, 32) must be consistent with array size 32",
      "",
      "Stacktrace:",
      "  [1] (::Base.var\"#throw_dmrsa#289\")(dims::Tuple{Int64, Int64, Int64}, len::Int64)",
      "    @ Base .\\reshapedarray.jl:41",
      "  [2] reshape(a::Vector{Any}, dims::Tuple{Int64, Int64, Int64})",
      "    @ Base .\\reshapedarray.jl:45",
      "  [3] reshape(::Vector{Any}, ::Int64, ::Int64, ::Vararg{Int64})",
      "    @ Base .\\reshapedarray.jl:117",
      "  [4] adjoint",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\lib\\array.jl:124 [inlined]",
      "  [5] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\ZygoteRules\\OgCVT\\src\\adjoint.jl:66 [inlined]",
      "  [6] _pullback",
      "    @ .\\In[25]:3 [inlined]",
      "  [7] _pullback(ctx::Zygote.Context{false}, f::var\"#47#49\", args::Vector{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      "  [8] macro expansion",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\layers\\basic.jl:53 [inlined]",
      "  [9] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\layers\\basic.jl:53 [inlined]",
      " [10] _pullback(::Zygote.Context{false}, ::typeof(Flux._applychain), ::Tuple{var\"#47#49\", Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, var\"#48#50\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}, ::Vector{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [11] _pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Flux\\Nzh8J\\src\\layers\\basic.jl:51 [inlined]",
      " [12] _pullback(ctx::Zygote.Context{false}, f::Flux.Chain{Tuple{var\"#47#49\", Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, var\"#48#50\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, args::Vector{Any})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [13] _pullback",
      "    @ .\\In[26]:7 [inlined]",
      " [14] _pullback(ctx::Zygote.Context{false}, f::var\"#51#52\"{Vector{Any}, Vector{Any}}, args::Flux.Chain{Tuple{var\"#47#49\", Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, var\"#48#50\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface2.jl:0",
      " [15] pullback(f::Function, cx::Zygote.Context{false}, args::Flux.Chain{Tuple{var\"#47#49\", Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, var\"#48#50\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface.jl:44",
      " [16] pullback",
      "    @ C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface.jl:42 [inlined]",
      " [17] withgradient(f::Function, args::Flux.Chain{Tuple{var\"#47#49\", Flux.Recur{Flux.LSTMCell{Matrix{Float32}, Matrix{Float32}, Vector{Float32}, Tuple{Matrix{Float32}, Matrix{Float32}}}, Tuple{Matrix{Float32}, Matrix{Float32}}}, var\"#48#50\", Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}})",
      "    @ Zygote C:\\Users\\dpsha\\.julia\\packages\\Zygote\\TSj5C\\src\\compiler\\interface.jl:132",
      " [18] top-level scope",
      "    @ In[26]:6"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "\n",
    "for epoch in 1:num_epochs\n",
    "    for (x, y) in train_set\n",
    "        val, grads = Flux.withgradient(model) do m\n",
    "            ŷ = m(x)\n",
    "            loss_val = Flux.Losses.mse(ŷ, y)\n",
    "        end\n",
    "\n",
    "        if !isfinite(val)\n",
    "            @warn \"loss is $val on item $epoch\" epoch\n",
    "            continue\n",
    "        end\n",
    "        if length(grads) > 0\n",
    "            Flux.Optimise.update!(opt, ps, grads[1])\n",
    "        else\n",
    "            @warn \"no gradients on item $epoch\" epoch\n",
    "        end\n",
    "    end\n",
    "    # Optionally, you can evaluate the model on the validation set and print the validation loss here\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the validation set\n",
    "val_predictions = [model(reshape(x, size(x, 1), 1, size(x, 2))) for x in X_val]\n",
    "val_loss = mean(loss_function(ŷ, y) for (ŷ, y) in zip(val_predictions, y_val))\n",
    "println(\"Validation Loss: $val_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function preprocess_new_midi(csv_file::String)\n",
    "    df = CSV.read(csv_file, DataFrame)\n",
    "    if size(df)[1] < 500\n",
    "        println(\"MIDI file is too short (< 500 rows).\")\n",
    "        return nothing\n",
    "    end\n",
    "    input = Matrix{Float32}(df[1:500,Not(:anomalies)])\n",
    "    if sum(df.anomalies[1:500]) > 0\n",
    "        println(\"MIDI file contains $(sum(df.anomalies[1:500])) anomalies.\")\n",
    "    end\n",
    "    return input\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the new MIDI file\n",
    "new_midi_file = \"assets/anomalous/liz_rhap15_0.3.csv\"\n",
    "new_midi_input = preprocess_new_midi(new_midi_file)\n",
    "\n",
    "# Check if the preprocessing was successful (the file had at least 500 rows)\n",
    "if new_midi_input !== nothing\n",
    "    # Reshape the input array to match the model's input shape\n",
    "    new_midi_input = reshape(new_midi_input, size(new_midi_input, 1), 1, size(new_midi_input, 2))\n",
    "    println(new_midi_input)    \n",
    "    # Predict the number of errors in the new MIDI file\n",
    "    num_errors = model(new_midi_input)\n",
    "\n",
    "    println(\"Predicted number of errors: \", num_errors[1])\n",
    "else\n",
    "    println(\"Prediction cannot be performed due to insufficient data.\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
